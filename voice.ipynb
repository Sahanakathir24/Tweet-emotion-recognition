{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['full_path'] = glob.glob('kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio')\n",
    "df['fname'] = df['full_path'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "features = {'modality':{'01':'full-AV',\n",
    "                        '02':'video-only', \n",
    "                        '03':'audio-only'},\n",
    "            'vocal channel':{'01':'speech', \n",
    "                             '02':'song'},\n",
    "            'emotion':{'01':'neutral',\n",
    "                       '02':'calm',\n",
    "                       '03':'happy',\n",
    "                       '04':'sad',\n",
    "                       '05':'angry',\n",
    "                       '06':'fearful',\n",
    "                       '07':'disgust',\n",
    "                       '08':'surprised'},\n",
    "            'emotional intensity':{'01':'normal', \n",
    "                                   '02':'strong'},\n",
    "            'statement':{'01':'Kids are talking by the door', \n",
    "                         '02':'Dogs are sitting by the door'},\n",
    "            'repetition':{'01':'1st repetition', \n",
    "                          '02':'2nd repetition'}}\n",
    "c = 0\n",
    "for feature in features:\n",
    "    df[feature] = df['fname'].apply(lambda x: features[feature][re.split(r\"-|.wav|\\(|\\)\", x)[c]])\n",
    "    c += 1\n",
    "\n",
    "# df['Actor'] = df['fname'].apply(lambda x: int(re.split(r\"-|.wav|\\(|\\)\", x)[-2]))\n",
    "df['sex'] = df['fname'].apply(lambda x: 'female' if int(re.split(r\"-|.wav|\\(|\\)\", x)[-2]) % 2 == 0 else 'male')\n",
    "\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,12),dpi = 60)\n",
    "\n",
    "gs = fig.add_gridspec(3,3)\n",
    "gs.update(wspace = 0.2, hspace = 0.5)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:1, :1]) #distribution plot\n",
    "ax2 = fig.add_subplot(gs[:1, 1:2])\n",
    "ax3 = fig.add_subplot(gs[:1, 2:3])\n",
    "ax4 = fig.add_subplot(gs[1:2, :1])\n",
    "ax5 = fig.add_subplot(gs[1:2, 1:2])\n",
    "ax6 = fig.add_subplot(gs[1:2, 2:])\n",
    "ax7 = fig.add_subplot(gs[2:, :1])\n",
    "\n",
    "axes = [ax1, ax2, ax3, ax4, ax5, ax6, ax7]\n",
    "\n",
    "# sns.violinplot(x='Emotion', y='audio_duration', data=df[df['Emotional intensity'] == 'normal'], order=df['Emotion'].unique(), ax=ax1)\n",
    "# sns.violinplot(x='Emotion', y='audio_duration', data=df[df['Emotional intensity'] == 'strong'], order=df['Emotion'].unique(), ax=ax2)\n",
    "\n",
    "# # setting of axes; visibility of axes and spines turn off\n",
    "columns = df.columns[2:]\n",
    "for i in range(len(axes)):\n",
    "    sns.countplot(x=columns[i], data=df, ax=axes[i])\n",
    "#     ax.axes.get_yaxis().set_visible(False)\n",
    "    axes[i].set_xticklabels(axes[i].get_xticklabels(), fontsize=11.5, fontweight='bold')\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_yticklabels(axes[i].get_yticklabels(), fontsize=10, fontweight='bold')\n",
    "    axes[i].set_ylabel('Count', fontsize=10, fontweight ='bold')\n",
    "    axes[i].set_title(columns[i], size=18)\n",
    "#     axes[i].set_facecolor('white')\n",
    "    \n",
    "#     for loc in ['left', 'right', 'top', 'bottom']:\n",
    "#         ax.spines[loc].set_visible(False)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "fig.text(0.42, 1, 'Variance Between Features' ,{'font': 'Serif', 'size': '25','weight':'bold', 'color':'black'})\n",
    "# fig.text(0.15, 1, '', {'font':'Serif', 'color': 'black', 'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    librosa.display.waveshow(data, sr=sr)\n",
    "    plt.title('Waveplot')\n",
    "#     plt.show()\n",
    "\n",
    "def create_mfcc(data, sr):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=30)\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "#     plt.show()\n",
    "\n",
    "def create_melspectrogram(data, sr):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    melspec = librosa.feature.melspectrogram(y=data, n_mels = 60)   \n",
    "    logspec = librosa.amplitude_to_db(melspec)\n",
    "    librosa.display.specshow(logspec, sr=sr, x_axis='time', y_axis='hz')   \n",
    "    plt.title('Mel Spectrogram')\n",
    "    plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_audio = df[(df.emotion == 'happy') & (df.statement == 'Kids are talking by the door')].iloc[0].full_path\n",
    "sad_audio = df[(df.emotion == 'sad') & (df.statement == 'Kids are talking by the door')].iloc[0].full_path\n",
    "angry_audio = df[(df.emotion == 'angry') & (df.statement == 'Kids are talking by the door')].iloc[0].full_path\n",
    "neutral_audio = df[(df.emotion == 'neutral') & (df.statement == 'Kids are talking by the door')].iloc[0].full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(happy_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(happy_audio)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(sad_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(sad_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(angry_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(angry_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(neutral_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(neutral_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_audio = df[(df.emotion == 'disgust') & (df.statement == 'Kids are talking by the door') & (df['emotional intensity']== 'normal')].iloc[0].full_path\n",
    "strong_audio = df[(df.emotion == 'disgust') & (df.statement == 'Kids are talking by the door') & (df['emotional intensity'] == 'strong')].iloc[0].full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(normal_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(normal_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(strong_audio)\n",
    "create_waveplot(data, sampling_rate)\n",
    "create_mfcc(data, sampling_rate)\n",
    "create_melspectrogram(data, sampling_rate)\n",
    "ipd.Audio(strong_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_duration(path):\n",
    "    data, sr = librosa.load(path)\n",
    "    return data.shape[0]/sr\n",
    "\n",
    "df['audio_duration'] = df['full_path'].apply(get_audio_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,10),dpi = 60)\n",
    "\n",
    "gs = fig.add_gridspec(10,24)\n",
    "gs.update(wspace = 1, hspace = 0.05)\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:]) #distribution plot\n",
    "sns.violinplot(x='emotion', y='audio_duration', data=df, order=df['emotion'].unique(), ax=ax1)\n",
    "axes=[ax1]\n",
    "# setting of axes; visibility of axes and spines turn off\n",
    "for ax in axes:\n",
    "#     ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_xticklabels(df['emotion'].unique(), fontsize=20, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Audio Duration', fontweight ='bold')\n",
    "    ax.set_facecolor('white')\n",
    "    for loc in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[loc].set_visible(False)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax1.text(0, 6.4, 'Are the Audio Durations Different per Emotion?' ,{'font': 'Serif', 'size': '25','weight':'bold', 'color':'black'})\n",
    "ax1.text(0, 6,'The majority of the emotions mean audio durations are around 3.5 seconds, while disgust and angry are slightly longer. \\n\\\n",
    "Neutral has the shortest durations while disgust and angry have the longest durations.', {'font':'Serif', 'color': 'black', 'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,10),dpi = 60)\n",
    "\n",
    "gs = fig.add_gridspec(10,25)\n",
    "gs.update(wspace = 1, hspace = 0.05)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:, :12]) #distribution plot\n",
    "ax2 = fig.add_subplot(gs[:, 13:])\n",
    "sns.violinplot(x='emotion', y='audio_duration', data=df[df['emotional intensity'] == 'normal'], order=df['emotion'].unique(), ax=ax1)\n",
    "sns.violinplot(x='emotion', y='audio_duration', data=df[df['emotional intensity'] == 'strong'], order=df['emotion'].unique(), ax=ax2)\n",
    "\n",
    "axes=[ax1, ax2]\n",
    "# setting of axes; visibility of axes and spines turn off\n",
    "for ax in axes:\n",
    "#     ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.set_xticklabels(df['emotion'].unique(), fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Audio Duration', fontweight ='bold')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    for loc in ['left', 'right', 'top', 'bottom']:\n",
    "        ax.spines[loc].set_visible(False)\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax1.set_title('Normal', size=18, weight='bold')\n",
    "ax2.set_title('Strong', size=18, weight='bold')\n",
    "\n",
    "ax1.text(0, 6.4, 'How does Emotional Intensity Effect Duration?' ,{'font': 'Serif', 'size': '25','weight':'bold', 'color':'black'})\n",
    "ax1.text(0, 6,'When the emotional intensity is \"strong\" the audio duration is longer. There is no neutral \\nemotion when the emotional intensity is \"strong\".', {'font':'Serif', 'color': 'black', 'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (30,10),dpi = 60)\n",
    "\n",
    "gs = fig.add_gridspec(10,24)\n",
    "gs.update(wspace = 1, hspace = 0.05)\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[:]) #distribution plot\n",
    "sns.violinplot(x='sex', y='audio_duration', data=df, ax=ax1)\n",
    "axes=[ax1]\n",
    "# setting of axes; visibility of axes and spines turn off\n",
    "for ax in axes:\n",
    "#     ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=20, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=13, fontweight='bold')\n",
    "    ax.set_ylabel('Audio Duration', fontweight ='bold')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "#     for loc in ['left', 'right', 'top', 'bottom']:\n",
    "#         ax.spines[loc].set_visible(False)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "ax1.text(-0.4, 6.4, 'Are the Audio Durations Different for the Sexes?' ,{'font': 'Serif', 'size': '25','weight':'bold', 'color':'black'})\n",
    "ax1.text(-0.4, 6, 'Interestingly the male has the longest and shortest audio durations. The mean duration is the same for the sexes, \\nbut there are more female audios that are around the mean.', {'font':'Serif', 'color': 'black', 'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['modality', 'vocal channel', 'emotional intensity', 'statement', 'repetition'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "from sklearn.preprocessing import normalize, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_and_offset(path, sr=16000, input_length=48000):\n",
    "    data, _ = librosa.load(path, sr=sr, res_type='kaiser_fast')\n",
    "    if len(data) > input_length:\n",
    "        max_offset = len(data) - input_length\n",
    "        offset = np.random.randint(max_offset)\n",
    "        data = data[offset:(input_length+offset)]\n",
    "    else:\n",
    "        if input_length > len(data):\n",
    "            max_offset = input_length - len(data)\n",
    "            offset = np.random.randint(max_offset)\n",
    "        else:\n",
    "            offset = 0\n",
    "        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "        \n",
    "    return data\n",
    "def speed_pitch(data):\n",
    "    length_change = np.random.uniform(low=0.8, high = 1)\n",
    "    speed_fac = 1.2  / length_change \n",
    "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
    "    minlen = min(data.shape[0], tmp.shape[0])\n",
    "    data *= 0\n",
    "    data[0:minlen] = tmp[0:minlen]\n",
    "    return data\n",
    "\n",
    "def noise(data):\n",
    "    noise_amp = 0.05*np.random.uniform()*np.amax(data)\n",
    "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = librosa.load(df.iloc[0].full_path)\n",
    "create_waveplot(data, _)\n",
    "ipd.Audio(data, rate=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_pitched = speed_pitch(data)\n",
    "create_waveplot(speed_pitched, _)\n",
    "ipd.Audio(speed_pitched, rate=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noised = noise(data)\n",
    "create_waveplot(noised, _)\n",
    "ipd.Audio(noised, rate=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = [], []\n",
    "x_aug, y_aug = [], []\n",
    "for r in tqdm(df.values):\n",
    "    x = padding_and_offset(r[0])\n",
    "    x_data.append(x)\n",
    "    y_data.append(r[2:4])\n",
    "    \n",
    "    x_aug.append(speed_pitch(x))\n",
    "    x_aug.append(noise(x))\n",
    "\n",
    "    y_aug.extend([r[2:4], r[2:4]])\n",
    "    \n",
    "    \n",
    "x_data, y_data = np.array(x_data), np.array(y_data)\n",
    "x_aug, y_aug = np.array(x_aug), np.array(y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size=0.8, stratify=y_data, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(e_data, s_data):\n",
    "    e_encoder = LabelEncoder()\n",
    "    e_encoder = e_encoder.fit(list(df.emotion.unique()))\n",
    "    e_encoded = to_categorical(e_encoder.transform(e_data))\n",
    "\n",
    "    s_encoder = LabelEncoder()\n",
    "    s_encoder = s_encoder.fit(list(df.sex.unique()))\n",
    "    s_encoded = to_categorical(s_encoder.transform(s_data))\n",
    "    \n",
    "    return e_encoded, s_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_y , s_y = [], []\n",
    "for e, s in y_train:\n",
    "    e_y.append(e)\n",
    "    s_y.append(s)\n",
    "    \n",
    "e_y_train, s_y_train = encode(e_y, s_y)\n",
    "\n",
    "e_y , s_y = [], []\n",
    "for e, s in y_test:\n",
    "    e_y.append(e)\n",
    "    s_y.append(s)\n",
    "    \n",
    "e_y_test, s_y_test = encode(e_y, s_y)\n",
    "\n",
    "e_y_train_aug , s_y_train_aug = [], []\n",
    "for e, s in y_aug:\n",
    "    e_y_train_aug.append(e)\n",
    "    s_y_train_aug.append(s)\n",
    "\n",
    "    \n",
    "e_y_train_aug, s_y_train_aug = encode(e_y_train_aug, s_y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_aug = np.concatenate((x_train, x_aug), axis=0)\n",
    "e_y_train_aug = np.concatenate((e_y_train, e_y_train_aug), axis=0)\n",
    "s_y_train_aug = np.concatenate((s_y_train, s_y_train_aug), axis=0)\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(x_train_aug)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(e_y_train_aug)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(s_y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(data):\n",
    "    MFCC = librosa.feature.mfcc(y=data, sr=16000, n_mfcc=30)\n",
    "    MFCC = np.expand_dims(MFCC, axis=-1)\n",
    "    return MFCC\n",
    "\n",
    "def get_melspec(data):\n",
    "    melspec = librosa.feature.melspectrogram(y=data, n_mels=60)   \n",
    "    logspec = librosa.amplitude_to_db(melspec)\n",
    "    logspec = np.expand_dims(logspec, axis=-1)\n",
    "    return logspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mfcc = []\n",
    "x_test_mfcc = []\n",
    "x_train_aug_mfcc = []\n",
    "\n",
    "for i in x_train:\n",
    "    mfcc = get_mfcc(i)\n",
    "    x_train_mfcc.append(mfcc)\n",
    "\n",
    "for i in x_test:\n",
    "    mfcc = get_mfcc(i)\n",
    "    x_test_mfcc.append(mfcc)\n",
    "\n",
    "for i in x_train_aug:\n",
    "    mfcc = get_mfcc(i)\n",
    "    x_train_aug_mfcc.append(mfcc)\n",
    "    \n",
    "x_train_mfcc, x_test_mfcc, x_train_aug_mfcc = np.array(x_train_mfcc), np.array(x_test_mfcc), np.array(x_train_aug_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_melspec = []\n",
    "x_test_melspec = []\n",
    "x_train_aug_melspec = []\n",
    "\n",
    "for i in x_train:\n",
    "    melspec = get_melspec(i)\n",
    "    x_train_melspec.append(melspec)\n",
    "\n",
    "for i in x_test:\n",
    "    melspec = get_melspec(i)\n",
    "    x_test_melspec.append(melspec)\n",
    "\n",
    "for i in x_train_aug:\n",
    "    melspec = get_melspec(i)\n",
    "    x_train_aug_melspec.append(melspec)\n",
    "    \n",
    "x_train_melspec, x_test_melspec, x_train_aug_melspec = np.array(x_train_melspec), np.array(x_test_melspec), np.array(x_train_aug_melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, Dropout, Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_model(input_len=48000, n_emotions=8, n_sex=2):\n",
    "    inputs = Input(shape=(input_len, 1))\n",
    "    x = Conv1D(16, 3, activation='relu', padding='valid')(inputs)\n",
    "    x = Conv1D(16, 3, activation='relu', padding='valid')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu', padding='valid')(x)\n",
    "    x = Conv1D(32, 3, activation='relu', padding='valid')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "x = MaxPool1D(4)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, activation='relu', padding='valid')(x)\n",
    "    x = Conv1D(256, 3, activation='relu', padding='valid')(x)\n",
    "#     x = BatchNormalization()(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    emotion_output = Dense(n_emotions, activation='softmax', name='emotion_output')(x)\n",
    "    sex_output = Dense(n_sex, activation='sigmoid', name='sex_output')(x)\n",
    "    \n",
    "    model = Model(inputs, [emotion_output, sex_output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_2d_mfcc_model(shape, n_emotions=8, n_sex=2):\n",
    "    inputs = Input(shape=shape)\n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    emotion_output = Dense(n_emotions, activation='softmax', name='emotion_output')(x)\n",
    "    sex_output = Dense(n_sex, activation='sigmoid', name='sex_output')(x)\n",
    "    \n",
    "    model = Model(inputs, [emotion_output, sex_output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_2d_melspec_model(shape, n_emotions=8, n_sex=2):\n",
    "    inputs = Input(shape=shape)\n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "     x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "      emotion_output = Dense(n_emotions, activation='softmax', name='emotion_output')(x)\n",
    "    sex_output = Dense(n_sex, activation='sigmoid', name='sex_output')(x)\n",
    "    \n",
    "    model = Model(inputs, [emotion_output, sex_output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name_model):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20),\n",
    "        ModelCheckpoint(name_model, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    ]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d = get_1d_model()\n",
    "model_1d.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_1d = model_1d.fit(x_train, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_split=0.2, callbacks=get_callbacks('best_1d.h5'), epochs=100, batch_size=32)\n",
    "history_1d = model_1d.fit(x_train, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_data=(x_test, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_1d.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1d.history['emotion_output_accuracy'])\n",
    "plt.plot(history_1d.history['sex_output_accuracy'])\n",
    "plt.plot(history_1d.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_1d.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1d_aug = get_1d_model()\n",
    "model_1d_aug.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_1d_aug = model_1d_aug.fit(x_train_aug, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_split=0.2, callbacks=get_callbacks('best_1d_aug.h5'), epochs=100, batch_size=32)\n",
    "history_1d_aug = model_1d_aug.fit(x_train_aug, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_data=(x_test, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_1d_aug.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1d_aug.history['emotion_output_accuracy'])\n",
    "plt.plot(history_1d_aug.history['sex_output_accuracy'])\n",
    "plt.plot(history_1d_aug.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_1d_aug.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mfcc = get_2d_mfcc_model((30, 94, 1))\n",
    "model_mfcc.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_mfcc = model_mfcc.fit(x_train_mfcc, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_split=0.2, callbacks=get_callbacks('best_mfcc.h5'), epochs=100, batch_size=32)\n",
    "history_mfcc = model_mfcc.fit(x_train_mfcc, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_data=(x_test_mfcc, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_mfcc.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mfcc.history['emotion_output_accuracy'])\n",
    "plt.plot(history_mfcc.history['sex_output_accuracy'])\n",
    "plt.plot(history_mfcc.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_mfcc.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mfcc_aug = get_2d_mfcc_model((30, 94, 1))\n",
    "model_mfcc_aug.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_mfcc_aug = model_mfcc_aug.fit(x_train_aug_mfcc, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_split=0.2, callbacks=get_callbacks('best_mfcc_aug.h5'), epochs=100, batch_size=32)\n",
    "history_mfcc_aug = model_mfcc_aug.fit(x_train_aug_mfcc, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_data=(x_test_mfcc, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_mfcc_aug.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_mfcc_aug.history['emotion_output_accuracy'])\n",
    "plt.plot(history_mfcc_aug.history['sex_output_accuracy'])\n",
    "plt.plot(history_mfcc_aug.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_mfcc_aug.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_melspec = get_2d_melspec_model((60, 94, 1))\n",
    "model_melspec.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_melspec = model_melspec.fit(x_train_melspec, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_split=0.2, callbacks=get_callbacks('best_melspec.h5'), epochs=100, batch_size=32)\n",
    "history_melspec = model_melspec.fit(x_train_melspec, {'emotion_output':e_y_train, 'sex_output':s_y_train}, validation_data=(x_test_melspec, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_melspec.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_melspec.history['emotion_output_accuracy'])\n",
    "plt.plot(history_melspec.history['sex_output_accuracy'])\n",
    "plt.plot(history_melspec.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_melspec.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_melspec_aug = get_2d_melspec_model((60, 94, 1))\n",
    "model_melspec_aug.compile(optimizer=Adam(), loss={\"emotion_output\" : \"categorical_crossentropy\", \"sex_output\":\"binary_crossentropy\"}, metrics=['accuracy'])\n",
    "# history_melspec_aug = model_melspec_aug.fit(x_train_aug_melspec, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_split=0.2, callbacks=get_callbacks('best_melspec_aug.h5'), epochs=100, batch_size=32)\n",
    "history_melspec_aug = model_melspec_aug.fit(x_train_aug_melspec, {'emotion_output':e_y_train_aug, 'sex_output':s_y_train_aug}, validation_data=(x_test_melspec, {'emotion_output':e_y_test, 'sex_output':s_y_test}), callbacks=get_callbacks('best_melspec_aug.h5'), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_melspec_aug.history['emotion_output_accuracy'])\n",
    "plt.plot(history_melspec_aug.history['sex_output_accuracy'])\n",
    "plt.plot(history_melspec_aug.history['val_emotion_output_accuracy'])\n",
    "plt.plot(history_melspec_aug.history['val_sex_output_accuracy'])\n",
    "plt.legend(['emotion_output_accuracy', 'sex_output_accuracy', 'val_emotion_output_accuracy', 'val_sex_output_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n",
    "\n",
    "for model in [model_1d, model_1d_aug, model_mfcc, model_mfcc_aug, model_melspec, model_melspec_aug]:\n",
    "    with open(Pkl_Filename, 'wb') as file:  \n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_y , s_y = [], []\n",
    "for e, s in y_test:\n",
    "    e_y.append(e)\n",
    "    s_y.append(s)\n",
    "    \n",
    "e_y_test, s_y_test = encode(e_y, s_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "e_y_test, s_y_test = np.argmax(e_y_test, axis=1), np.argmax(s_y_test, axis=1)\n",
    "\n",
    "def get_prediction(model, x):\n",
    "    y_pred_e, y_pred_s = model.predict(x)\n",
    "    y_pred_e, y_pred_s = np.argmax(y_pred_e, axis=1), np.argmax(y_pred_s, axis=1)\n",
    "    return y_pred_e, y_pred_s\n",
    "\n",
    "def display_results(y_pred_e, y_pred_s, y_true_e, y_true_s):\n",
    "    e_conf_matrix = confusion_matrix(y_true_e, y_pred_e)\n",
    "    s_conf_matrix = confusion_matrix(y_true_s, y_pred_s)\n",
    "    e_df = pd.DataFrame(e_conf_matrix, index=list(df.emotion.unique()), columns=list(df.emotion.unique()))\n",
    "    s_df = pd.DataFrame(s_conf_matrix, index=list(df.sex.unique()), columns=list(df.sex.unique()))\n",
    "    print(classification_report(y_true_e, y_pred_e, target_names=list(df.emotion.unique())))\n",
    "    sns.heatmap(e_df, annot=True, fmt='g')\n",
    "    plt.show()\n",
    "    print(classification_report(y_true_s, y_pred_s, target_names=list(df.sex.unique())))\n",
    "    sns.heatmap(s_df, annot=True, fmt='g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_1d, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_1d_aug, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_mfcc, x_test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_mfcc_aug, x_test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_melspec, x_test_melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_e, y_pred_s = get_prediction(model_melspec_aug, x_test_melspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(y_pred_e, y_pred_s, e_y_test, s_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'my_model3.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
